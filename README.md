# Recoding Core Machine Learning Concepts in Numpy

<p align="center">
  <img alt="GitHub" src="https://img.shields.io/github/license/gavin-bauer/recode-core-ml-from-scratch">
</p>

---

## Synopsis
In order to understand the details of the most frequent algorithms in Machine Learning, I have recoded the core concepts in Python using only Numpy (for computations) and Matplotlib (for visualizations).

## Table of content
* Gradient Descent Regressor: [Python script](gradient-descent-regressor.py) | [Detailed explanations](https://gavin-bauer.netlify.com/2020/03/gradient-descent-regressor/)


## Built with
* [NumPy](http://www.numpy.org/)
* [Matplotlib](http://matplotlib.org/)

## Author
* **Gavin Bauer** - Data Analyst of 5+ years experience | Current: ðŸ¦‰[@KeringGroup](https://www.kering.com/) | Past: âš¡[@Total](https://www.total.com/en), ðŸŒ±[@YvesRocherFR](https://groupe-rocher.com/en)

## License
This code is licensed under the MIT License - see the [LICENSE](LICENSE) file for details

## Acknowledgements | Inspiration
* Andrew Ng's amazing Machine Learning [course](https://www.coursera.org/learn/machine-learning)
* Emil Wallner's post [The History of Deep Learning](https://medium.com/@emilwallner/the-history-of-deep-learning-explored-through-6-code-snippets-d0a0e8545202)
